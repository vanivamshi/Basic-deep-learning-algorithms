# -*- coding: utf-8 -*-
"""nbiot_fog.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o7naCewbhQZ4U0vKkEanuxdoLOwAdJEs
"""

#pip install -U -q PyDrive

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials


# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# dataset available at - https://www.kaggle.com/datasets/sachin26240/vehicularfogcomputing

import pandas as pd

# to get the id part of the file
id = link.split("/")[-2]

downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cpu_usage2.csv')

data = pd.read_csv('cpu_usage2.csv')
print(data)



# start code here

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL
import time

from sklearn.model_selection import train_test_split # to split the data into two parts
import tensorflow as tf
from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed, Flatten
from tensorflow.keras.models import Sequential
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import MinMaxScaler

data = data.iloc[:, 1:]

# Create a new column with continuous numbers
data["ID"] = range(1, len(data) + 1)

# Reorder the columns to have "ID" as the first column
data = data[["ID"] + [col for col in data.columns if col != "ID"]]

# Define CoS parameters
# security
print('Bandwidth usage cost')
print(data['Bandwidth usage cost'].min())
print(data['Bandwidth usage cost'].mean())
print(data['Bandwidth usage cost'].max())

# reliability
print('Memory usage cost')
print(data['Memory usage cost'].min())
print(data['Memory usage cost'].mean())
print(data['Memory usage cost'].max())

# data storage
print('CPU usage cost')
print(data['CPU usage cost'].min())
print(data['CPU usage cost'].mean())
print(data['CPU usage cost'].max())

# data location
print('Task_1 (cost)')
print(data['Task_1 (cost)'].min())
print(data['Task_1 (cost)'].mean())
print(data['Task_1 (cost)'].max())

# delay sensitivity
print('Task_1 (sec)')
print(data['Task_1 (sec)'].min())
print(data['Task_1 (sec)'].mean())
print(data['Task_1 (sec)'].max())

# Add column called 'Action' containing CoS parameters based on QoS parameters
data['Action'] = ''

# Use conditional statements to populate the 'Action' column
#MC
data.loc[(data['Bandwidth usage cost'] > 0.75*data['Bandwidth usage cost'].max()) & (data['Memory usage cost'] > 0.75*data['Memory usage cost'].max()) & (data['CPU usage cost'] < 0.75*data['CPU usage cost'].max()) & (data['Task_1 (cost)'] < 0.25*data['Task_1 (cost)'].max()) & (data['Task_1 (sec)'] < 0.75*data['Task_1 (sec)'].max()), 'Action'] = 'MC'
#RT
data.loc[(data['Bandwidth usage cost'] > 0.25*data['Bandwidth usage cost'].max()) & (data['Bandwidth usage cost'] < 0.75*data['Bandwidth usage cost'].max()) & (data['Memory usage cost'] > 0.25*data['Memory usage cost'].max()) & (data['Memory usage cost'] < 0.75*data['Memory usage cost'].max()) & (data['CPU usage cost'] > 0.25*data['CPU usage cost'].max()) & (data['Task_1 (cost)'] > 0.25*data['Task_1 (cost)'].max()) & (data['Task_1 (sec)'] < 0.75*data['Task_1 (sec)'].max()), 'Action'] = 'RT'
#IN
data.loc[(data['Bandwidth usage cost'] > 0.75*data['Bandwidth usage cost'].max()) & (data['Memory usage cost'] < 0.25*data['Memory usage cost'].max()) & (data['CPU usage cost'] < 0.75*data['CPU usage cost'].max()) & (data['Task_1 (cost)'] > 11.0) & (data['Task_1 (cost)'] < 0.75*data['Task_1 (cost)'].max()) & (data['Task_1 (sec)'] < 0.75*data['Task_1 (sec)'].max()), 'Action'] = 'IN'
#CB
data.loc[(data['Bandwidth usage cost'] > 0.75*data['Bandwidth usage cost'].max()) & (data['Memory usage cost'] > 0.25*data['Memory usage cost'].max()) & (data['Memory usage cost'] < 0.75*data['Memory usage cost'].max()) & (data['CPU usage cost'] > 0.25*data['CPU usage cost'].max()) & (data['Task_1 (cost)'] > 0.75*data['Task_1 (cost)'].max()) & (data['Task_1 (sec)'] < 0.75*data['Task_1 (sec)'].max()), 'Action'] = 'CB'
#BE
data.loc[~((data['Action'] == 'MC') | (data['Action'] == 'RT') | (data['Action'] == 'IN') | (data['Action'] == 'CB')), 'Action'] = 'BE'

data['Action']

# split dataseta s test and train datasets
# Define a dictionary to map the values
mapping = {'MC': 1, 'RT': 2, 'IN': 3, 'CB':4, 'BE':5}

# Use the replace method to rename the values in the 'Action' column
data['Action'] = data['Action'].replace(mapping)

# split dataset based on Action values to train of them seperately
df = data[data['Action'] == 5]

#columns_to_drop = [
#    'Action',
#    'Number of instructions (109 instructions)',
#    'Memory required (MB)',
#    'Input file size (MB)',
#    'Output file size (MB)'
#]

# Use the drop method to remove the specified columns
#df.drop(columns=columns_to_drop, inplace=True)
selected_columns = [
    'ID', 'Task_3 (cost)', 'Task_4 (cost)', 'Task_5 (cost)'
]
df_selected = df[selected_columns]
X = df_selected.drop(columns=['Task_3 (cost)'])
y = df_selected[['Task_3 (cost)']]



# LSTM
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# start deep learning models
scaler = MinMaxScaler(feature_range=(0, 1))

print(X_train.shape)
print(y_train.shape)

#X = np.array(X_train).reshape(-1,1)
#y = np.array(y_train).reshape(-1,1)
#X = X_train
#y = y_train

X_train = scaler.fit_transform(X_train)
y_train = scaler.fit_transform(y_train)

print(X_train.shape)
print(y_train.shape)

print(X_test.shape)
print(y_test.shape)

X_train = X_train.reshape(60,3,1)
y_train = y_train.reshape(60,1,1)

X_test = np.array(X_test).reshape(-1,1)
y_test = np.array(y_test).reshape(-1,1)

X_test = X_test.reshape(26,3,1)
y_test = y_test.reshape(26,1,1)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

# LSTM model definition
model = Sequential([
                    LSTM(60, input_shape=(3,1)),
                    Dropout(0.3),
                    RepeatVector(120),
                    LSTM(60, return_sequences=True),
                    #Dropout(0.2),
                    #RepeatVector(120),
                    #LSTM(120, return_sequences=True),
                    TimeDistributed(Dense(60)),
                    TimeDistributed(Dense(1)),
                    Flatten(),
                    Dense(1, activation='sigmoid')
])

model.compile(loss='mse', optimizer='adam')
model.summary()

history = model.fit(X_train, y_train, epochs=20, batch_size=1, verbose=2, validation_data=(X_test, y_test))
history

X_pred = X_test[0:1]
print(y_test[0:1])

start_time = time.time()
pred = model.predict(np.array(X_pred))
stop_time = time.time()
print(stop_time-start_time)

pred
testPredict = scaler.inverse_transform(pred)
testPredict

testScore = np.sqrt(tf.keras.metrics.mean_squared_error([[18.3742]], testPredict[:,0]))
print('Test Score: %f RMSE' % (testScore))

mse = tf.keras.metrics.mean_squared_error([[18.3742]], testPredict).numpy()
mae = tf.keras.metrics.mean_absolute_error([[18.3742]], testPredict).numpy()
print(mse)
print(mae)



# built-in LSTM model
X = df_selected.drop(columns=['ID','Task_3 (cost)','Task_5 (cost)'])
print(X.tail(1))
y = df_selected[['Task_3 (cost)']]
yp = y.tail(1)
print(yp)

import torch
import torch.nn as nn
import torch.optim as optim

# Define your input data (X) and target data (y)
X = np.array(X)  # Convert your data to a NumPy array
y = np.array(y)  # Convert your data to a NumPy array
yp = np.array(yp)

#print(X.shape)
#print(y.shape)
X = X.reshape(86,1)
y = y.reshape(86,1)
yp = yp.reshape(1,1)

# Convert NumPy arrays to PyTorch tensors
X = torch.tensor(X, dtype=torch.float32)
y = torch.tensor(y, dtype=torch.float32)
yp = torch.tensor(yp, dtype=torch.float32)

# Define hyperparameters
input_size = 1  # The input size should match the number of features in your data
hidden_size = 60  # You can adjust this based on your problem
num_layers = 9  # Number of LSTM layers
output_size = y.shape[1]  # The output size should match the dimensionality of your target

learning_rate = 0.001
num_epochs = 100

# Define the LSTM model
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[-1, :])
        return out

model = LSTMModel(input_size, hidden_size, num_layers, output_size)

# Define loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Train the model
for epoch in range(num_epochs):
    # Forward pass
    outputs = model(X)
    loss = criterion(outputs, y)

    # Backward pass and optimization
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

# Make predictions
with torch.no_grad():
    predictions = model(y)

# Convert the predictions from PyTorch tensors to NumPy arrays
predictions = predictions.numpy()

# Print the predictions
print(predictions)

from sklearn.metrics import mean_absolute_error, mean_squared_error

# Assuming you have the actual target values in a NumPy array named 'actual_values'
actual_values = np.array([9.3559])  # Replace 'actual_values' with your actual target data

print('LSTM')
# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(actual_values, predictions)
print(f"Mean Absolute Error (MAE): {mae:.2f}")

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(actual_values, predictions)
print(f"Mean Squared Error (MSE): {mse:.2f}")

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")





# MLP
# Import MLPClassifer
from sklearn.neural_network import MLPRegressor
#import numpy as np
import timeit

#X = np.array([-5,-4,-3,-2,-1,0,1,2,3,4]).reshape(-1,1)
#y = np.array([27,28,29,30,31,32,33,34,35,36]).reshape(-1,1)

start = timeit.default_timer()
# Create model object
clf = MLPRegressor(hidden_layer_sizes=(5,11,5), # 5,8,5; 5,10,5; 5,11,5
                    alpha=1e-3,
                    solver='sgd',
                    shuffle = True,
                    random_state=5,
                    verbose=True,
                    learning_rate_init=0.00045) #0.0002; 0.0002; 0.0002

clf.fit(X, y)

stop = timeit.default_timer()
print(stop-start)

X_test = [[10.3967]]
start = timeit.default_timer()
ypred=clf.predict(X_test)
print(ypred)

stop = timeit.default_timer()
print(stop-start)

import math
rmse = math.sqrt(tf.keras.metrics.mean_squared_error(np.array([9.3559]), ypred).numpy())
mse = tf.keras.metrics.mean_squared_error(np.array([9.3559]), ypred).numpy()
mae = tf.keras.metrics.mean_absolute_error(np.array([9.3559]), ypred).numpy()
print(rmse)
print(mse)
print(mae)







# CNN
X = df_selected[['Task_4 (cost)']]
y = df_selected[['Task_3 (cost)']]
print(X.shape)
print(y.shape)
#train_X = X_train.reshape(86, 3, 1, 1)
#test_X = X_test.reshape(26, 3,1, 1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = MinMaxScaler(feature_range=(0, 1))

X_train = scaler.fit_transform(X_train)
y_train = scaler.fit_transform(y_train)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

X_train = np.array(X_train).reshape(-1,1)
y_train = np.array(y_train).reshape(-1,1)
X_test = np.array(X_test).reshape(-1,1)
y_test = np.array(y_test).reshape(-1,1)

X_train = X_train.reshape(60,1,1,1)
y_train = y_train.reshape(60,1,1,1)
X_test = X_test.reshape(26,1,1,1)
y_test = y_test.reshape(26,1,1,1)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

from keras.models import Sequential,Model#,Input
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import BatchNormalization, GaussianNoise
from keras.layers import LeakyReLU, Reshape

fashion_model = Sequential()
fashion_model.add(Conv2D(1, kernel_size=(1, 1),activation='linear',input_shape=(1,1,1),padding='same'))
fashion_model.add(LeakyReLU(alpha=0.1))
fashion_model.add(MaxPooling2D((2, 2),padding='same'))
fashion_model.add(Conv2D(10, (1, 1), activation='linear',padding='same'))
fashion_model.add(tf.keras.layers.Reshape((10,1,1)))
#fashion_model.add(GaussianNoise(0.1))
#fashion_model.add(LeakyReLU(alpha=0.1))
#fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))
fashion_model.add(Conv2D(5, (3, 3), activation='linear',padding='same'))
#fashion_model.add(LeakyReLU(alpha=0.1))
#fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))
fashion_model.add(Flatten())
#fashion_model.add(Dense(128, activation='linear'))
fashion_model.add(LeakyReLU(alpha=0.1))
fashion_model.add(Dense(1, activation='softmax'))
#fashion_model.add(BatchNormalization(synchronized=True))

fashion_model.compile(loss='mae', optimizer='adam',metrics=['accuracy'])
fashion_model.summary()

history = fashion_model.fit(X_train, y_train, epochs=20, batch_size=1, verbose=2, validation_data=(X_test, y_test))
history

X_pred = X_test[0:1]
print(y_test[0:1])

start_time = time.time()
pred = fashion_model.predict(np.array(X_pred))
stop_time = time.time()
print(stop_time-start_time)

pred
testPredict = scaler.inverse_transform(pred)
testPredict

testScore = np.sqrt(tf.keras.metrics.mean_squared_error([[18.3742]], testPredict[:,0]))
print('Test Score: %f RMSE' % (testScore))
mse = tf.keras.metrics.mean_squared_error([[18.3742]], testPredict).numpy()
mae = tf.keras.metrics.mean_absolute_error([[18.3742]], testPredict).numpy()
print(mse)
print(mae)







# Multilayer autoencoder
X = df_selected[['Task_4 (cost)']]
y = df_selected[['Task_3 (cost)']]
print(X.shape)
print(y.shape)
#train_X = X_train.reshape(86, 3, 1, 1)
#test_X = X_test.reshape(26, 3,1, 1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = MinMaxScaler(feature_range=(0, 1))

X_train = scaler.fit_transform(X_train)
y_train = scaler.fit_transform(y_train)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

X_train = np.array(X_train).reshape(-1,1)
y_train = np.array(y_train).reshape(-1,1)
X_test = np.array(X_test).reshape(-1,1)
y_test = np.array(y_test).reshape(-1,1)

X_train = X_train.reshape(60,1,1)
y_train = y_train.reshape(60,1,1)
X_test = X_test.reshape(26,1,1)
y_test = y_test.reshape(26,1,1)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

model = Sequential([
                    Dense(11, activation='relu', input_shape=(1,1)),
                    Dense(9, activation='relu'),
                    Dense(11, activation='relu'),
                    Dense(13, activation='relu'),
                    Dense(1, activation='sigmoid'),
                    Flatten()
])

model.compile(loss='mae', optimizer='adam')
model.summary()

X_pred = X_test[0:1]
print(y_test[0:1])

start_time = time.time()
pred = model.predict(np.array(X_pred))
stop_time = time.time()
print(stop_time-start_time)

pred
testPredict = scaler.inverse_transform(pred)
testPredict

testScore = np.sqrt(tf.keras.metrics.mean_squared_error([[18.3742]], testPredict[:,0]))
print('Test Score: %f RMSE' % (testScore))
mse = tf.keras.metrics.mean_squared_error([[18.3742]], testPredict).numpy()
mae = tf.keras.metrics.mean_absolute_error([[18.3742]], testPredict).numpy()
print(mse)
print(mae)





# Simple autoencoder

model = Sequential([
                    Dense(1, activation='tanh', input_shape=(1,1)),
                    Dropout(0.2),
                    Dense(1, activation='sigmoid'),
                    Flatten()
])

model.compile(loss='mae', optimizer='adam')
model.summary()

X_pred = X_test[0:1]
print(y_test[0:1])

start_time = time.time()
pred = model.predict(np.array(X_pred))
stop_time = time.time()
print(stop_time-start_time)

pred
testPredict = scaler.inverse_transform(pred)
testPredict

testScore = np.sqrt(tf.keras.metrics.mean_squared_error([[18.3742]], testPredict[:,0]))
print('Test Score: %f RMSE' % (testScore))
mse = tf.keras.metrics.mean_squared_error([[18.3742]], testPredict).numpy()
mae = tf.keras.metrics.mean_absolute_error([[18.3742]], testPredict).numpy()
print(mse)
print(mae)





# Restricted boltzmann machines (RBM)
X = df_selected[['Task_4 (cost)']]
y = df_selected[['Task_3 (cost)']]
print(X.shape)
print(y.shape)
#train_X = X_train.reshape(86, 3, 1, 1)
#test_X = X_test.reshape(26, 3,1, 1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = MinMaxScaler(feature_range=(0, 1))

X_train = scaler.fit_transform(X_train)
y_train = scaler.fit_transform(y_train)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

# Define an RBM layer
rbm_layer = Dense(units=1, activation='sigmoid')

# Create a Sequential model to stack RBMs
dbn_model = Sequential()

# Add RBM layers to the DBN model
for _ in range(2):
    dbn_model.add(rbm_layer)

# Compile and train the DBN as needed
dbn_model.compile(optimizer='adam', loss='mse')
dbn_model.fit(X_train, y_train, epochs=20, batch_size=1, verbose=2, validation_data=(X_test, y_test))

# Evaluate the DBN
#evaluation = dbn_model.evaluate(test_data, test_labels)

X_pred = X_test[0:1]
print(y_test[0:1])
pred = dbn_model.predict(np.array(X_pred))
pred
testPredict = scaler.inverse_transform(pred)
testPredict

testScore = np.sqrt(tf.keras.metrics.mean_squared_error([[18.3742]], testPredict[:,0]))
print('Test Score: %f RMSE' % (testScore))
mse = tf.keras.metrics.mean_squared_error([[18.3742]], testPredict).numpy()
mae = tf.keras.metrics.mean_absolute_error([[18.3742]], testPredict).numpy()
print(mse)
print(mae)